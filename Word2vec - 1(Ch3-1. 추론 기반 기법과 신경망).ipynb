{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-1-1. 통계 기반 기법의 문제점\n",
    " - 통계 기반 기법: 대규모 말뭉치를 다룰 때 상당한 컴퓨팅 자원과 장시간 계산을 필요로 함.\n",
    " - 추론 기반 기법: 신경망이 한 번에 소량(mini batch)의 학습 샘플씩 반복해서 학습하며 가중치를 갱신.\n",
    " - 통계 기반 기법 vs 추론 기반 기법\n",
    "  * 학습 데이터를 한꺼번에 처리(배치 학습) vs 학습 데이터의 일부를 사용해 순차적으로 학습(미니 배치)\n",
    "  * 계산량이 큰 작업을 처리하기 어려움 vs 여러 머신, GPU를 이용한 병렬계산 가능(높은 학습 속도)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-1-2. 추론 기반 기법 개요\n",
    " - 추론 기반 기법: 반복하여 추론 문제를 풀면서 단어의 출현 패턴을 학습하는것.\n",
    " - ex. 'you ( ? ) goodbye and I say hello.' --> 맥락을 사용해 \"?\"에 들어갈 단어 추측.\n",
    " - 추론 기반 기법의 전체 그림:\n",
    "  * 신경망으로 구성된 모델을 구성 → 모델에 맥락 정보를 입력 → 각 단어의 출현 확률 출력\n",
    "  * 말뭉치를 사용해 모델이 올바른 추측을 내놓을 수 있도로 학습시킴."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-1-3. 신경망에서의 단어 처리\n",
    " - 단어의 3가지 표현 방법\n",
    "   * 1) 텍스트\n",
    "   * 2) ID화\n",
    "   * 3) one-hot encoding\n",
    " - one-hot encoding: 벡터 원소 중 하나만 1이고 나머지는 모두 0인 벡터로 단어를 변환하는 것.\n",
    " - 단어를 '고정 길이의 벡터'로 변환하여 신경망에서 단어를 처리할 수 있도록 함.\n",
    " - 순서:\n",
    "   * 1) 어휘 수 만큼의 원소를 갖는 벡터 준비\n",
    "   * 2) 인덱스가 단어 ID와 같은 원소를 1로, 나머지는 모두 0으로 설정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.79881752  1.38066065 -0.52264997]]\n"
     ]
    }
   ],
   "source": [
    "#완전연결계층(모든 입력층 노드들 각각이 이웃 층의 모든 노드들과 연결된 것)\n",
    "import numpy as np\n",
    "\n",
    "c = np.array([[1, 0, 0, 0, 0, 0, 0]]) # 입력  : 단어 ID에 해당하는 원소만 1이고 나머지는 0인 one-hot\n",
    "W = np.random.randn(7, 3)             # 가중치\n",
    "h = np.matmul(c, W)                   # 중간 노드 : 가중치의 행벡터 하나를 뽑아낸 것\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.86338785  1.02766897  0.96002888]]\n"
     ]
    }
   ],
   "source": [
    "#위의 코드를 Matmul 계층으로 수행.\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.layers import MatMul\n",
    "\n",
    "c = np.array([[1, 0, 0, 0, 0, 0, 0]])\n",
    "W = np.random.randn(7, 3)            \n",
    "layer = MatMul(W)\n",
    "h = layer.forward(c)   #Matmul 계층에 가중치 W를 설정하고  forward() 메서드로 순전파 수행.\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(-1, 2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
