{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3-1. 파이썬으로 말뭉치 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#말뭉치로 사용할 예시 문장\n",
    "text = 'You say goodbye and I say hello.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you say goodbye and i say hello  .\n",
      "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '', '.']\n"
     ]
    }
   ],
   "source": [
    "#문장 -> 단어 단위로 분할\n",
    "text = text.lower()          #모든 문자를 소문자로 변환\n",
    "text = text.replace('.', ' .')\n",
    "print(text)\n",
    "\n",
    "words = text.split(' ')      #공백을 기준으로 분할 #정규표현식을 사용하는 게 정석! \n",
    "                             #re.split('(\\W+)?.text')를 호출하면 단어 단위로 분할할 수 있음.\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어에 ID를 부여하고, ID의 리스트로 이용할 수 있도록 손질.\n",
    "                   # Key = ID, Value = 단어\n",
    "word_to_id = {}    #단어 -> ID로의 변환\n",
    "id_to_word = {}    #ID -> 단어로의 변환\n",
    "\n",
    "for word in words:    #단어 단위로 분할된 words의 각 원소를 처음부터 하나씩 살펴본다.\n",
    "    if word not in word_to_id:   #word_to_id에 없는 단어는 word_to_id, id_to_word에 각각 새로운 id와 단어를 추가.\n",
    "        new_id = len(word_to_id) #추가 시점의 딕셔너리 길이가 새로운 단어의 ID로 설정됨(0, 1, 2, ....)\n",
    "        word_to_id[word] = new_id\n",
    "        id_to_word[new_id] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '', 7: '.'}\n",
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '': 6, '.': 7}\n"
     ]
    }
   ],
   "source": [
    "print(id_to_word)\n",
    "\n",
    "print(word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "say\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#dict -> 단어 ID를 검색하거나, ID로 단어를 검색할 수 있다.\n",
    "print(id_to_word[1])\n",
    "\n",
    "print(word_to_id['and'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "#마지막으로 '단어 목록'을 '단어 ID 목록'으로 변환\n",
    "import numpy as np\n",
    "\n",
    "corpus = [word_to_id[w] for w in words] \n",
    "#comprehension(내포) 표기를 사용 -> 변환 '단어 목록'을 '단어 ID 목록'으로 변환 -> 다시 numpy 배열로 반환\n",
    "#내포: 리스트, 딕셔너리 등의 반복문 처리를 간단하게 하는 기법.\n",
    "#ex. xs = [1, 2, 3, 4]에서 각 원소를 제곱한 새로운 리스트를 생성하려면?\n",
    "# [xs**2 for x in xs]\n",
    "corpus = np.array(corpus)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이상의 전처리 과정을 함수화하기\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "    \n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "        \n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "    \n",
    "    return corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5] {'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5} {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello'}\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "print(corpus, word_to_id, id_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3-4. 동시행렬 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주목하는 단어 주변에 어떤 단어가 몇 번이나 등장하는가 집계하는 통계 기반 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "#1단계: 위에서 사용한 말뭉치와 전처리 함수 사용 -> 전처리 진행\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.util import preprocess\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "print(corpus)\n",
    "\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2단계: 각 단어의 맥락에 해당하는 단어의 빈도를 세어 보기\n",
    "#window size = 1, ID = 0인 you 부터 시작.\n",
    "#you의 맥락(1개): say\n",
    "#맥락으로써 등장하는 단어의 빈도:\n",
    "#      you   say   goodbye   and   i   hello   .\n",
    "#you    0     1       0       0    0     0     0\n",
    "#say    1     0       1       0    1     1     0\n",
    "#.........\n",
    "# .     0     0       0       0    0     1     0\n",
    "\n",
    "#위와 같이 모든 단어에 동시발생하는 단어를 표에 정리한 것을 '동시발생 행렬(co-occurence matrix)'라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#동시발생 행렬 구현(수동)\n",
    "C = np.array([\n",
    "    [0, 1, 0, 0, 0, 0, 0], #you\n",
    "    [1, 0, 1, 0, 1, 1, 0], #say   \n",
    "    [0, 1, 0, 1, 0, 0, 0], #goodbye\n",
    "    [0, 0, 1, 0, 1, 0, 0], #and\n",
    "    [0, 1, 0, 1, 0, 0, 0], #i\n",
    "    [0, 1, 0, 0, 0, 0, 1], #hello\n",
    "    [0, 0, 0, 0, 0, 1, 0]  #.\n",
    "], dtype = np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0]\n",
      "[0 1 0 1 0 0 0]\n",
      "[0 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(C[0])   #ID = 0인 단어의 벡터 표현\n",
    "print(C[4])\n",
    "print(C[word_to_id['goodbye']])  #\"goodbye\"의 벡터 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#동시발생 행렬 구현(자동)\n",
    "#함수로 작성할 수 있음.\n",
    "\n",
    "#단어 ID의 리스트, 어휘 수, 윈도우 크기를 인수로 받음.\n",
    "def create_co_matrix(corpus, vocab_size, window_size = 1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype = np.int32)  #먼저, co_matrix를 0으로 채워진 2차원 배열로 초기화.\n",
    "    \n",
    "    for idx, word_id in enumerate(corpus):    #말뭉치(corpus)의 모든 단어 각각에 대해 윈도우에 포함된 주변 단어를 세어나감.\n",
    "        for i in range(1, window_size + 1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "            \n",
    "            if left_idx >= 0:                #corpus의 왼쪽 끝과 오른쪽 끝 경계를 벗어나지 않는지 확인.\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "                \n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "                \n",
    "    return co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-a9cdae270995>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcreate_co_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-2959776939cc>\u001b[0m in \u001b[0;36mcreate_co_matrix\u001b[1;34m(corpus, vocab_size, window_size)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mright_idx\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mcorpus_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mright_word_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mright_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 \u001b[0mco_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_word_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mco_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "create_co_matrix(text, 7, window_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3-5. 벡터 간 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#코사인 유사도를 파이썬 함수로 구현해 보자.\n",
    "def cos_similarity(x, y):\n",
    "    nx = x / np.sqrt(np.sum(x**2))  #x의 정규화 : 벡터 x의 각 원소를 제곱한 값을 다 더한 값에 제곱근 씌움. \n",
    "    ny = y / np.sqrt(np.sum(y**2))  #y의 정규화\n",
    "    return np.dot(nx, ny)\n",
    "\n",
    "#인수 x, y는 numpy 배열이라고 가정한다.\n",
    "#각 벡터를 정규화한 후 두 벡터의 내적을 구하기.\n",
    "\n",
    "#But, 문제가 있음: 인수로 제로 벡터(=원소가 모두 0인 벡터)가 들어오면 '0으로 나누기(divide by zero) 오류' 발생."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'0으로 나누기 오류' 해결방법: 나눌 때 분모에 작은 값을 더해주는 것.\n",
    "\n",
    "#1e-8은 거의 0에 가까운 아주 작은 값. 최종 계산에는 거의 영향을 주지 않되 오류는 막아준다.\n",
    "def cos_similarity(x, y, eps = 1e-8):\n",
    "    nx = x/np.sqrt(np.sum(x**2) + eps)\n",
    "    ny = y/np.sqrt(np.sum(y**2) + eps)\n",
    "    return np.dot(nx, ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067691154799\n"
     ]
    }
   ],
   "source": [
    "#위 함수를 이용해 'you'와 'I'의 유사도 구하기\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.util import preprocess, create_co_matrix, cos_similarity\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "c0 = C[word_to_id['you']]\n",
    "c1 = C[word_to_id['i']]\n",
    "print(cos_similarity(c0, c1))  #0.7071... -1 <= 코사인 유사도 <= 1 이므로 꽤 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3-6. 유사 단어의 랭킹 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#어떤 단어가 검색어로 주어지면, 그 검색어와 비슷한 단어를 유사도 순으로 출력하는 함수를 만들자.\n",
    "\n",
    "#most_similar함수의 5개 인자\n",
    "## 1. query: 검색어(단어)\n",
    "## 2. word_to_id: 단어에서 단어 ID로의 딕셔너리\n",
    "## 3. id_to_word: 단어 ID에서 단어로의 딕셔너리\n",
    "## 4. word_matrix: 단어 벡터들을 한 데 모은 행렬. 각 행에는 대응하는 단어의 벡터가 저장되어있다고 가정.\n",
    "## 5. top: 상위 몇 개까지 출력할지 결정.\n",
    "\n",
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top = 5):\n",
    "    #1)검색어를 꺼낸다.\n",
    "    if query not in word_to_id:\n",
    "        print(\"%s(을)를 찾을 수 없습니다.\"%query)\n",
    "        return\n",
    "    \n",
    "    print('\\n[query]' + query)\n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "    \n",
    "    #2)코사인 유사도 계산.\n",
    "    vocab_size = len(id_to_word)\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "        \n",
    "    #3)코사인 유사도를 기준으로 내림차순(값이 높은 순서대로)으로 출력\n",
    "    #similarity 배열에 담긴 원소의 인덱스를 내림차순으로 정렬 후 상위 원소들을 출력\n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():  #argsort(): 배열 인덱스의 정렬 변경. \n",
    "                                           #numpy 배열의 원소를 오름차순으로 정렬하며, \n",
    "                                           #반환값은 배열의 인덱스.\n",
    "        if id_to_word[i] == query:\n",
    "            continue\n",
    "        print(' %s: %s'%(id_to_word[i], similarity[i]))\n",
    "        \n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0]\n",
      "[0 2 1]\n"
     ]
    }
   ],
   "source": [
    "#argsort 예시\n",
    "x = np.array([100, -20, 2])\n",
    "print(x.argsort())    #[100, -20, 2] -> 오름차순 정렬[-20, 2, 100] -> 원래 인덱스 순서대로 출력하면 1, 2, 0\n",
    "print((-x).argsort()) #x를 큰 순서대로 정렬하려면... 100, 2, -20의 역순으로 출력해야 한다. \n",
    "                      #따라서 x에 -를 곱해주면 내림차순으로 출력함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " goodbye: 0.7071067691154799\n",
      " i: 0.7071067691154799\n",
      " hello: 0.7071067691154799\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "#위에서 생성한 most_similar()함수 사용하여 'you' 검색하고 유사한 단어들 출력.\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.util import preprocess, create_co_matrix, most_similar\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "most_similar('you', word_to_id, id_to_word, C, top=5)   # 단어: 코사인유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
